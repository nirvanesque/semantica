{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Hawksight-AI/semantica/blob/main/cookbook/introduction/05_Entity_Extraction.ipynb)\n",
    "\n",
    "#  Entity Extraction - Comprehensive Guide\n",
    "\n",
    "##  Overview\n",
    "\n",
    "This notebook provides a **comprehensive guide** to extracting named entities from text using Semantica's powerful NER (Named Entity Recognition) modules. You'll learn to use multiple extractors, methods, and advanced features to identify and classify entities in text.\n",
    "\n",
    "**Documentation**: [API Reference](https://semantica.readthedocs.io/reference/semantic_extract/)\n",
    "\n",
    "###  Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "-  Extract entities using `NERExtractor` and `NamedEntityRecognizer`\n",
    "-  Understand different extraction methods (pattern, regex, ML, HuggingFace, LLM)\n",
    "-  Use `EntityClassifier` to classify and group entities\n",
    "-  Apply `EntityConfidenceScorer` to assess extraction quality\n",
    "-  Create custom entity patterns with `CustomEntityDetector`\n",
    "-  Configure extraction parameters for optimal results\n",
    "-  Process multiple documents efficiently\n",
    "-  Handle edge cases and errors gracefully\n",
    "\n",
    "###  What You'll Learn\n",
    "\n",
    "| Component | Purpose | When to Use |\n",
    "|-----------|---------|-------------|\n",
    "| `NERExtractor` | Core entity extraction | Quick, simple extraction |\n",
    "| `NamedEntityRecognizer` | Advanced NER with configuration | Fine-tuned control needed |\n",
    "| `EntityClassifier` | Classify and group entities | Organizing extracted entities |\n",
    "| `EntityConfidenceScorer` | Score entity confidence | Quality assessment |\n",
    "| `CustomEntityDetector` | Domain-specific entities | Custom patterns needed |\n",
    "\n",
    "---\n",
    "\n",
    "##  Installation\n",
    "\n",
    "Install Semantica from PyPI:\n",
    "\n",
    "```bash\n",
    "pip install semantica\n",
    "# Or with all optional dependencies:\n",
    "pip install semantica[all]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantica in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.6.1)\n",
      "Requirement already satisfied: spacy>=3.4.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.8.11)\n",
      "Requirement already satisfied: transformers>=4.20.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.53.2)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.2.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.2.1)\n",
      "Requirement already satisfied: rdflib>=6.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (7.4.0)\n",
      "Requirement already satisfied: networkx>=2.8.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.5)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.10.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.13.2)\n",
      "Requirement already satisfied: plotly>=5.10.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (5.17.0)\n",
      "Requirement already satisfied: requests>=2.28.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.12.3)\n",
      "Requirement already satisfied: lxml>=4.9.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (6.0.2)\n",
      "Requirement already satisfied: pypdf2>=2.10.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.0.1)\n",
      "Requirement already satisfied: python-docx>=0.8.11 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.1.2)\n",
      "Requirement already satisfied: openpyxl>=3.0.10 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.1.5)\n",
      "Requirement already satisfied: pillow>=9.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (10.4.0)\n",
      "Requirement already satisfied: librosa>=0.9.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.11.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.9.0.80)\n",
      "Requirement already satisfied: faiss-cpu>=1.7.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.9.0)\n",
      "Requirement already satisfied: weaviate-client>=3.15.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.18.1)\n",
      "Requirement already satisfied: qdrant-client>=1.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.12.2)\n",
      "Requirement already satisfied: neo4j>=5.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (6.0.3)\n",
      "Requirement already satisfied: falkordb>=1.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.2.2)\n",
      "Requirement already satisfied: pymongo>=4.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.15.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.0.23)\n",
      "Requirement already satisfied: psycopg2-binary>=2.9.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.9.9)\n",
      "Requirement already satisfied: pymysql>=1.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.1.2)\n",
      "Requirement already satisfied: redis>=4.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (6.4.0)\n",
      "Requirement already satisfied: celery>=5.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (5.3.4)\n",
      "Requirement already satisfied: kafka-python>=2.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.3.0)\n",
      "Requirement already satisfied: pulsar-client>=3.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (3.3.0)\n",
      "Requirement already satisfied: pika>=1.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.3.2)\n",
      "Requirement already satisfied: boto3>=1.24.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.36.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.12.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (12.27.1)\n",
      "Requirement already satisfied: google-cloud-storage>=2.5.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.18.2)\n",
      "Requirement already satisfied: pydantic>=1.10.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (2.12.3)\n",
      "Requirement already satisfied: click>=8.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (8.2.1)\n",
      "Requirement already satisfied: rich>=12.5.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (13.7.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (6.0.1)\n",
      "Requirement already satisfied: toml>=0.10.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.10.2)\n",
      "Requirement already satisfied: python-dotenv>=0.20.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.1.1)\n",
      "Requirement already satisfied: loguru>=0.6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.7.3)\n",
      "Requirement already satisfied: structlog>=22.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (24.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.14.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.18.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.12.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.12.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.59b0)\n",
      "Requirement already satisfied: fastapi>=0.78.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.120.4)\n",
      "Requirement already satisfied: uvicorn>=0.18.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.38.0)\n",
      "Requirement already satisfied: pytest>=7.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (7.4.3)\n",
      "Requirement already satisfied: pytest-cov>=3.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (7.0.0)\n",
      "Requirement already satisfied: pytest-asyncio>=0.19.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (0.21.1)\n",
      "Requirement already satisfied: black>=22.6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (23.11.0)\n",
      "Requirement already satisfied: isort>=5.10.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (5.12.0)\n",
      "Requirement already satisfied: flake8>=4.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (7.3.0)\n",
      "Requirement already satisfied: mypy>=0.971 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (1.17.1)\n",
      "Requirement already satisfied: pre-commit>=2.19.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantica) (4.4.0)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob>=12.12.0->semantica) (1.35.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob>=12.12.0->semantica) (43.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob>=12.12.0->semantica) (4.14.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-storage-blob>=12.12.0->semantica) (0.7.2)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from azure-core>=1.30.0->azure-storage-blob>=12.12.0->semantica) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4>=4.11.0->semantica) (2.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=22.6.0->semantica) (1.0.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=22.6.0->semantica) (24.2)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=22.6.0->semantica) (0.11.2)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from black>=22.6.0->semantica) (3.11.0)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3>=1.24.0->semantica) (1.36.26)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3>=1.24.0->semantica) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3>=1.24.0->semantica) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<1.37.0,>=1.36.0->boto3>=1.24.0->semantica) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<1.37.0,>=1.36.0->boto3>=1.24.0->semantica) (1.26.20)\n",
      "Requirement already satisfied: billiard<5.0,>=4.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (4.2.1)\n",
      "Requirement already satisfied: kombu<6.0,>=5.3.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (5.5.3)\n",
      "Requirement already satisfied: vine<6.0,>=5.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (5.1.0)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (0.3.1)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (1.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from celery>=5.2.0->semantica) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.1.0->semantica) (0.4.6)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kombu<6.0,>=5.3.2->celery>=5.2.0->semantica) (5.3.1)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in c:\\users\\mohd kaif\\appdata\\roaming\\python\\python311\\site-packages (from click-repl>=0.2.0->celery>=5.2.0->semantica) (3.0.40)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.12.0->semantica) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.12.0->semantica) (2.22)\n",
      "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi>=0.78.0->semantica) (0.46.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi>=0.78.0->semantica) (0.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.0->semantica) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.0->semantica) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.0->semantica) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from starlette<0.50.0,>=0.40.0->fastapi>=0.78.0->semantica) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi>=0.78.0->semantica) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi>=0.78.0->semantica) (1.3.1)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flake8>=4.0.0->semantica) (0.7.0)\n",
      "Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flake8>=4.0.0->semantica) (2.14.0)\n",
      "Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from flake8>=4.0.0->semantica) (3.4.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-storage>=2.5.0->semantica) (2.36.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-storage>=2.5.0->semantica) (2.23.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-storage>=2.5.0->semantica) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-storage>=2.5.0->semantica) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-cloud-storage>=2.5.0->semantica) (1.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.5.0->semantica) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.5.0->semantica) (4.25.8)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.5.0->semantica) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->semantica) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->semantica) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->semantica) (4.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.28.0->semantica) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.28.0->semantica) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0dev,>=2.26.1->google-cloud-storage>=2.5.0->semantica) (0.6.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\mohd kaif\\appdata\\roaming\\python\\python311\\site-packages (from librosa>=0.9.0->semantica) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa>=0.9.0->semantica) (1.1.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from loguru>=0.6.0->semantica) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.5.0->semantica) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.5.0->semantica) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.5.0->semantica) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.5.0->semantica) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.5.0->semantica) (3.2.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from neo4j>=5.0.0->semantica) (2024.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa>=0.9.0->semantica) (0.44.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl>=3.0.10->semantica) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api>=1.12.0->semantica) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.12.0->semantica) (3.17.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-sdk>=1.12.0->semantica) (0.59b0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly>=5.10.0->semantica) (8.5.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pre-commit>=2.19.0->semantica) (3.5.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pre-commit>=2.19.0->semantica) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pre-commit>=2.19.0->semantica) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pre-commit>=2.19.0->semantica) (20.24.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mohd kaif\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery>=5.2.0->semantica) (0.2.9)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymongo>=4.2.0->semantica) (2.4.2)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytest>=7.1.0->semantica) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytest>=7.1.0->semantica) (1.5.0)\n",
      "Requirement already satisfied: coverage>=7.10.6 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from coverage[toml]>=7.10.6->pytest-cov>=3.0.0->semantica) (7.12.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client>=1.3.0->semantica) (1.68.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client>=1.3.0->semantica) (1.62.3)\n",
      "Requirement already satisfied: httpx>=0.20.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.3.0->semantica) (0.28.1)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client>=1.3.0->semantica) (2.10.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client>=1.3.0->semantica) (311)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client>=1.3.0->semantica) (80.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client>=1.3.0->semantica) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client>=1.3.0->semantica) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.3.0->semantica) (4.1.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.3.0->semantica) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.3.0->semantica) (4.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=12.5.0->semantica) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=12.5.0->semantica) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.5.0->semantica) (0.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.0.0->semantica) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.2.0->semantica) (0.30.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.20.0->semantica) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.20.0->semantica) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.20.0->semantica) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.20.0->semantica) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.0->semantica) (2023.10.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (0.20.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.4.0->semantica) (3.1.6)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.4.0->semantica) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.4.0->semantica) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.4.0->semantica) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.4.0->semantica) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.4.0->semantica) (1.17.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.4.0->semantica) (3.2.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->semantica) (1.13.3)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=2.19.0->semantica) (0.3.7)\n",
      "Requirement already satisfied: validators<1.0.0,>=0.34.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weaviate-client>=3.15.0->semantica) (0.35.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weaviate-client>=3.15.0->semantica) (1.6.0)\n",
      "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weaviate-client>=3.15.0->semantica) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy>=3.4.0->semantica) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mohd kaif\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.12.0->semantica) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~gno (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~gno (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~lotly (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ython-socketio (C:\\Users\\Mohd Kaif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install semantica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1: Basic Entity Extraction with NERExtractor\n",
    "\n",
    "Let's start with the simplest approach using `NERExtractor`. This class provides a straightforward interface for extracting named entities from text.\n",
    "\n",
    "### What is NERExtractor?\n",
    "\n",
    "`NERExtractor` is the core entity extraction class that:\n",
    "- Identifies named entities (people, organizations, locations, dates, etc.)\n",
    "- Returns entity objects with text, type, position, and confidence\n",
    "- Supports multiple extraction methods\n",
    "- Works out-of-the-box with sensible defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='font-family: monospace;'><h4>üß† Semantica - üìä Current Progress</h4><table style='width: 100%; border-collapse: collapse;'><tr><th>Status</th><th>Action</th><th>Module</th><th>Submodule</th><th>File</th><th>Time</th></tr><tr><td>‚úÖ</td><td>Semantica is extracting</td><td>üéØ semantic_extract</td><td>NERExtractor</td><td>-</td><td>1.08s</td></tr><tr><td>‚úÖ</td><td>Semantica is extracting</td><td>üéØ semantic_extract</td><td>NamedEntityRecognizer</td><td>-</td><td>2.50s</td></tr></table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted 13 entities:\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      " 1. Apple Inc.                     | Type: ORG          | Confidence: 1.00\n",
      " 2. Steve Jobs                     | Type: PERSON       | Confidence: 1.00\n",
      " 3. Steve Wozniak                  | Type: PERSON       | Confidence: 1.00\n",
      " 4. Ronald Wayne                   | Type: PERSON       | Confidence: 1.00\n",
      " 5. Cupertino                      | Type: GPE          | Confidence: 1.00\n",
      " 6. California                     | Type: GPE          | Confidence: 1.00\n",
      " 7. April 1, 1976                  | Type: DATE         | Confidence: 1.00\n",
      " 8. Tim Cook                       | Type: PERSON       | Confidence: 1.00\n",
      " 9. Steve Jobs                     | Type: PERSON       | Confidence: 1.00\n",
      "10. August 2011                    | Type: DATE         | Confidence: 1.00\n",
      "11. Apple                          | Type: ORG          | Confidence: 1.00\n",
      "12. One                            | Type: CARDINAL     | Confidence: 1.00\n",
      "13. Cupertino                      | Type: GPE          | Confidence: 1.00\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import NERExtractor\n",
    "\n",
    "# Initialize the extractor\n",
    "ner_extractor = NERExtractor()\n",
    "\n",
    "# Sample text with various entity types\n",
    "text = \"\"\"\n",
    "Apple Inc. is a technology company founded by Steve Jobs, Steve Wozniak, and Ronald Wayne \n",
    "in Cupertino, California on April 1, 1976. The company's current CEO is Tim Cook, who took \n",
    "over from Steve Jobs in August 2011. Apple is headquartered at One Apple Park Way in Cupertino.\n",
    "\"\"\"\n",
    "\n",
    "# Extract entities\n",
    "entities = ner_extractor.extract(text)\n",
    "\n",
    "print(f\" Extracted {len(entities)} entities:\\n\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, entity in enumerate(entities, 1):\n",
    "    # Handle both dict and object formats\n",
    "    entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "    entity_type = entity.get('type', entity.get('label', 'Unknown')) if isinstance(entity, dict) else entity.label\n",
    "    confidence = entity.get('confidence', 1.0) if isinstance(entity, dict) else getattr(entity, 'confidence', 1.0)\n",
    "    \n",
    "    print(f\"{i:2d}. {entity_text:30s} | Type: {entity_type:12s} | Confidence: {confidence:.2f}\")\n",
    "\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding Entity Objects\n",
    "\n",
    "Each extracted entity contains:\n",
    "\n",
    "| Attribute | Description | Example |\n",
    "|-----------|-------------|----------|\n",
    "| `text` | The entity text | \"Apple Inc.\" |\n",
    "| `label/type` | Entity category | \"ORG\" (Organization) |\n",
    "| `start_char` | Starting position | 0 |\n",
    "| `end_char` | Ending position | 10 |\n",
    "| `confidence` | Extraction confidence (0-1) | 0.95 |\n",
    "| `metadata` | Additional information | {\"method\": \"ml\"} |\n",
    "\n",
    "###  Common Entity Types\n",
    "\n",
    "- **PERSON**: People, including fictional characters\n",
    "- **ORG**: Companies, agencies, institutions\n",
    "- **GPE**: Countries, cities, states (Geo-Political Entities)\n",
    "- **LOC**: Non-GPE locations, mountain ranges, bodies of water\n",
    "- **DATE**: Absolute or relative dates or periods\n",
    "- **TIME**: Times smaller than a day\n",
    "- **MONEY**: Monetary values\n",
    "- **PERCENT**: Percentage values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: Visualizing Entities in Context\n",
    "\n",
    "Let's create a simple visualization to see entities highlighted in the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Entity Visualization:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "CARDINAL:\n",
      "  ‚Ä¢ One\n",
      "\n",
      "DATE:\n",
      "  ‚Ä¢ August 2011\n",
      "  ‚Ä¢ April 1, 1976\n",
      "\n",
      "GPE:\n",
      "  ‚Ä¢ California\n",
      "  ‚Ä¢ Cupertino\n",
      "\n",
      "ORG:\n",
      "  ‚Ä¢ Apple\n",
      "  ‚Ä¢ Apple Inc.\n",
      "\n",
      "PERSON:\n",
      "  ‚Ä¢ Steve Wozniak\n",
      "  ‚Ä¢ Ronald Wayne\n",
      "  ‚Ä¢ Steve Jobs\n",
      "  ‚Ä¢ Tim Cook\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def highlight_entities(text, entities):\n",
    "    \"\"\"\n",
    "    Create a simple text visualization with entity markers.\n",
    "    \"\"\"\n",
    "    # Group entities by type\n",
    "    entity_types = {}\n",
    "    for entity in entities:\n",
    "        entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "        entity_type = entity.get('type', entity.get('label', 'Unknown')) if isinstance(entity, dict) else entity.label\n",
    "        \n",
    "        if entity_type not in entity_types:\n",
    "            entity_types[entity_type] = []\n",
    "        entity_types[entity_type].append(entity_text)\n",
    "    \n",
    "    print(\"\\n Entity Visualization:\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for entity_type, entity_list in sorted(entity_types.items()):\n",
    "        unique_entities = list(set(entity_list))\n",
    "        print(f\"\\n{entity_type}:\")\n",
    "        for ent in unique_entities:\n",
    "            print(f\"  ‚Ä¢ {ent}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Visualize the extracted entities\n",
    "highlight_entities(text, entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ô∏è Step 3: Different Extraction Methods\n",
    "\n",
    "Semantica supports multiple extraction methods, each with different strengths:\n",
    "\n",
    "### Method Comparison\n",
    "\n",
    "| Method | Speed | Accuracy | Use Case | Requires |\n",
    "|--------|-------|----------|----------|----------|\n",
    "| **pattern** |  | ‚≠ê‚≠ê | Simple, predictable patterns | Nothing |\n",
    "| **regex** |  | ‚≠ê‚≠ê‚≠ê | Custom patterns, IDs, codes | Regex knowledge |\n",
    "| **ml** (spaCy) |  | ‚≠ê‚≠ê‚≠ê‚≠ê | General text, multiple languages | spaCy model |\n",
    "| **huggingface** |  | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Domain-specific, fine-tuned | HF model |\n",
    "| **llm** |  | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Complex, custom types | API key |\n",
    "\n",
    "Let's try different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Comparing Extraction Methods:\n",
      "\n",
      "================================================================================\n",
      "\n",
      " Method: PATTERN\n",
      "----------------------------------------\n",
      "Found 4 entities:\n",
      "  ‚Ä¢ Apple Inc (PERSON)\n",
      "  ‚Ä¢ Steve Jobs (PERSON)\n",
      "  ‚Ä¢ Apple Inc (ORG)\n",
      "  ‚Ä¢ 1976 (DATE)\n",
      "\n",
      " Method: REGEX\n",
      "----------------------------------------\n",
      "Found 8 entities:\n",
      "  ‚Ä¢ Apple Inc (PERSON)\n",
      "  ‚Ä¢ was founded by Steve Jobs in Cupertino (PERSON)\n",
      "  ‚Ä¢ California in (PERSON)\n",
      "  ‚Ä¢ Apple Inc (ORG)\n",
      "  ‚Ä¢ Apple Inc (GPE)\n",
      "\n",
      " Method: ML\n",
      "----------------------------------------\n",
      "Found 5 entities:\n",
      "  ‚Ä¢ Apple Inc. (ORG)\n",
      "  ‚Ä¢ Steve Jobs (PERSON)\n",
      "  ‚Ä¢ Cupertino (GPE)\n",
      "  ‚Ä¢ California (GPE)\n",
      "  ‚Ä¢ 1976 (DATE)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import NERExtractor\n",
    "\n",
    "sample_text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California in 1976.\"\n",
    "\n",
    "print(\" Comparing Extraction Methods:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Try different methods\n",
    "methods_to_try = [\"pattern\", \"regex\", \"ml\"]\n",
    "\n",
    "for method_name in methods_to_try:\n",
    "    try:\n",
    "        print(f\"\\n Method: {method_name.upper()}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        extractor = NERExtractor(method=method_name)\n",
    "        entities = extractor.extract(sample_text)\n",
    "        \n",
    "        print(f\"Found {len(entities)} entities:\")\n",
    "        for entity in entities[:5]:  # Show first 5\n",
    "            entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "            entity_type = entity.get('type', entity.get('label', 'Unknown')) if isinstance(entity, dict) else entity.label\n",
    "            print(f\"  ‚Ä¢ {entity_text} ({entity_type})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Ô∏è  Method '{method_name}' not available: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 4: Advanced Entity Recognition with NamedEntityRecognizer\n",
    "\n",
    "`NamedEntityRecognizer` provides more control over the extraction process through configuration parameters.\n",
    "\n",
    "### Key Parameters:\n",
    "\n",
    "- **`methods`**: List of extraction methods to use (e.g., `[\"spacy\", \"rule-based\"]`)\n",
    "- **`confidence_threshold`**: Minimum confidence score (0.0-1.0, default: 0.5)\n",
    "- **`merge_overlapping`**: Whether to merge overlapping entities (default: True)\n",
    "- **`include_standard_types`**: Include standard entity types (PERSON, ORG, LOC, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Advanced Entity Recognition Results:\n",
      "\n",
      "================================================================================\n",
      "\n",
      " Text 1: Tim Cook is the CEO of Apple Inc., based in Cupertino....\n",
      "   Found 3 entities:\n",
      "     ‚Ä¢ Tim Cook                  | PERSON     | Confidence: 1.00\n",
      "     ‚Ä¢ Apple Inc.                | ORG        | Confidence: 1.00\n",
      "     ‚Ä¢ Cupertino                 | GPE        | Confidence: 1.00\n",
      "\n",
      " Text 2: Microsoft Corporation, founded by Bill Gates, is headquarter...\n",
      "   Found 4 entities:\n",
      "     ‚Ä¢ Microsoft Corporation     | ORG        | Confidence: 1.00\n",
      "     ‚Ä¢ Bill Gates                | PERSON     | Confidence: 1.00\n",
      "     ‚Ä¢ Redmond                   | GPE        | Confidence: 1.00\n",
      "     ‚Ä¢ Washington                | GPE        | Confidence: 1.00\n",
      "\n",
      " Text 3: Amazon was founded by Jeff Bezos in Seattle in 1994....\n",
      "   Found 4 entities:\n",
      "     ‚Ä¢ Amazon                    | ORG        | Confidence: 1.00\n",
      "     ‚Ä¢ Jeff Bezos                | PERSON     | Confidence: 1.00\n",
      "     ‚Ä¢ Seattle                   | GPE        | Confidence: 1.00\n",
      "     ‚Ä¢ 1994                      | DATE       | Confidence: 1.00\n",
      "\n",
      " Text 4: Google was started by Larry Page and Sergey Brin at Stanford...\n",
      "   Found 4 entities:\n",
      "     ‚Ä¢ Google                    | ORG        | Confidence: 1.00\n",
      "     ‚Ä¢ Larry Page                | PERSON     | Confidence: 1.00\n",
      "     ‚Ä¢ Sergey Brin               | PERSON     | Confidence: 1.00\n",
      "     ‚Ä¢ Stanford University       | ORG        | Confidence: 1.00\n",
      "\n",
      " Total entities extracted: 15\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import NamedEntityRecognizer\n",
    "\n",
    "# Create recognizer with custom configuration\n",
    "ner = NamedEntityRecognizer(\n",
    "    methods=[\"spacy\"],  # Use spaCy for ML-based extraction\n",
    "    confidence_threshold=0.7,  # Only keep high-confidence entities\n",
    "    merge_overlapping=True,  # Merge overlapping entity mentions\n",
    "    include_standard_types=True  # Include standard entity types\n",
    ")\n",
    "\n",
    "# Sample texts for batch processing\n",
    "texts = [\n",
    "    \"Tim Cook is the CEO of Apple Inc., based in Cupertino.\",\n",
    "    \"Microsoft Corporation, founded by Bill Gates, is headquartered in Redmond, Washington.\",\n",
    "    \"Amazon was founded by Jeff Bezos in Seattle in 1994.\",\n",
    "    \"Google was started by Larry Page and Sergey Brin at Stanford University.\"\n",
    "]\n",
    "\n",
    "print(\" Advanced Entity Recognition Results:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_entities = []\n",
    "for i, text in enumerate(texts, 1):\n",
    "    entities = ner.extract_entities(text)\n",
    "    all_entities.extend(entities)\n",
    "    \n",
    "    print(f\"\\n Text {i}: {text[:60]}...\")\n",
    "    print(f\"   Found {len(entities)} entities:\")\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "        entity_type = entity.get('type', entity.get('label', 'Unknown')) if isinstance(entity, dict) else entity.label\n",
    "        confidence = entity.get('confidence', 1.0) if isinstance(entity, dict) else getattr(entity, 'confidence', 1.0)\n",
    "        print(f\"     ‚Ä¢ {entity_text:25s} | {entity_type:10s} | Confidence: {confidence:.2f}\")\n",
    "\n",
    "print(f\"\\n Total entities extracted: {len(all_entities)}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ô∏è Step 5: Entity Classification\n",
    "\n",
    "Use `EntityClassifier` to classify and group entities by type, and disambiguate similar entities.\n",
    "\n",
    "### What is EntityClassifier?\n",
    "\n",
    "The `EntityClassifier` helps you:\n",
    "- **Classify entities** by their type (normalize variations like \"ORG\" vs \"ORGANIZATION\")\n",
    "- **Group entities** by category for analysis\n",
    "- **Disambiguate entities** when multiple candidates exist\n",
    "- **Standardize entity types** across different extraction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ô∏è  Entity Classification Results:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DATE (1 entities):\n",
      "----------------------------------------\n",
      "  ‚Ä¢ 1994\n",
      "\n",
      "GPE (4 entities):\n",
      "----------------------------------------\n",
      "  ‚Ä¢ Cupertino\n",
      "  ‚Ä¢ Redmond\n",
      "  ‚Ä¢ Seattle\n",
      "  ‚Ä¢ Washington\n",
      "\n",
      "ORG (5 entities):\n",
      "----------------------------------------\n",
      "  ‚Ä¢ Amazon\n",
      "  ‚Ä¢ Apple Inc.\n",
      "  ‚Ä¢ Google\n",
      "  ‚Ä¢ Microsoft Corporation\n",
      "  ‚Ä¢ Stanford University\n",
      "\n",
      "PERSON (5 entities):\n",
      "----------------------------------------\n",
      "  ‚Ä¢ Bill Gates\n",
      "  ‚Ä¢ Jeff Bezos\n",
      "  ‚Ä¢ Larry Page\n",
      "  ‚Ä¢ Sergey Brin\n",
      "  ‚Ä¢ Tim Cook\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import EntityClassifier\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = EntityClassifier()\n",
    "\n",
    "# Classify the entities we extracted earlier\n",
    "classified = classifier.classify_entities(all_entities)\n",
    "\n",
    "print(\"Ô∏è  Entity Classification Results:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for entity_type, entity_list in sorted(classified.items()):\n",
    "    print(f\"\\n{entity_type} ({len(entity_list)} entities):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Get unique entity texts\n",
    "    unique_entities = set()\n",
    "    for entity in entity_list:\n",
    "        entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "        unique_entities.add(entity_text)\n",
    "    \n",
    "    for entity_text in sorted(unique_entities):\n",
    "        print(f\"  ‚Ä¢ {entity_text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 6: Confidence Scoring\n",
    "\n",
    "Use `EntityConfidenceScorer` to assess and improve the confidence scores of extracted entities.\n",
    "\n",
    "### Why Confidence Scoring?\n",
    "\n",
    "Confidence scores help you:\n",
    "- **Filter low-quality extractions** (e.g., only keep entities with confidence > 0.8)\n",
    "- **Prioritize entities** for manual review or validation\n",
    "- **Assess extraction quality** across different methods or texts\n",
    "- **Make informed decisions** about which entities to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Entity Confidence Scoring:\n",
      "\n",
      "================================================================================\n",
      " High Confidence (‚â•0.8): 15 entities\n",
      "Ô∏è  Medium Confidence (0.5-0.8): 0 entities\n",
      " Low Confidence (<0.5): 0 entities\n",
      "\n",
      " Confidence Distribution:\n",
      "----------------------------------------\n",
      "\n",
      "High Confidence Examples:\n",
      "  ‚Ä¢ Tim Cook (PERSON) - 1.00\n",
      "  ‚Ä¢ Apple Inc. (ORG) - 1.00\n",
      "  ‚Ä¢ Cupertino (GPE) - 1.00\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import EntityConfidenceScorer\n",
    "\n",
    "# Initialize confidence scorer\n",
    "scorer = EntityConfidenceScorer()\n",
    "\n",
    "# Score the entities\n",
    "scored_entities = scorer.score_entities(all_entities)\n",
    "\n",
    "print(\" Entity Confidence Scoring:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Group by confidence levels\n",
    "high_confidence = []\n",
    "medium_confidence = []\n",
    "low_confidence = []\n",
    "\n",
    "for entity in scored_entities:\n",
    "    confidence = entity.get('confidence', 1.0) if isinstance(entity, dict) else getattr(entity, 'confidence', 1.0)\n",
    "    \n",
    "    if confidence >= 0.8:\n",
    "        high_confidence.append(entity)\n",
    "    elif confidence >= 0.5:\n",
    "        medium_confidence.append(entity)\n",
    "    else:\n",
    "        low_confidence.append(entity)\n",
    "\n",
    "print(f\" High Confidence (‚â•0.8): {len(high_confidence)} entities\")\n",
    "print(f\"Ô∏è  Medium Confidence (0.5-0.8): {len(medium_confidence)} entities\")\n",
    "print(f\" Low Confidence (<0.5): {len(low_confidence)} entities\")\n",
    "\n",
    "print(\"\\n Confidence Distribution:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Show some examples from each category\n",
    "if high_confidence:\n",
    "    print(\"\\nHigh Confidence Examples:\")\n",
    "    for entity in high_confidence[:3]:\n",
    "        entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "        entity_type = entity.get('type', entity.get('label', 'Unknown')) if isinstance(entity, dict) else entity.label\n",
    "        confidence = entity.get('confidence', 1.0) if isinstance(entity, dict) else getattr(entity, 'confidence', 1.0)\n",
    "        print(f\"  ‚Ä¢ {entity_text} ({entity_type}) - {confidence:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 7: Custom Entity Detection\n",
    "\n",
    "Use `CustomEntityDetector` to define domain-specific entity patterns.\n",
    "\n",
    "### When to Use Custom Patterns?\n",
    "\n",
    "Custom patterns are useful for:\n",
    "- **Domain-specific entities** (e.g., product codes, invoice numbers)\n",
    "- **Structured identifiers** (e.g., email addresses, phone numbers)\n",
    "- **Industry-specific terms** (e.g., medical codes, legal citations)\n",
    "- **Custom formats** not recognized by standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Custom Entity Detection:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "EMAIL:\n",
      "  ‚Ä¢ support@apple.com\n",
      "  ‚Ä¢ tech@apple.com\n",
      "\n",
      "PHONE:\n",
      "  ‚Ä¢ 800-692-7753\n",
      "\n",
      "PRODUCT_CODE:\n",
      "  ‚Ä¢ SKU-12345\n",
      "\n",
      "URL:\n",
      "  ‚Ä¢ https://store.apple.com.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from semantica.semantic_extract import CustomEntityDetector\n",
    "import re\n",
    "\n",
    "# Define custom patterns\n",
    "custom_patterns = {\n",
    "    \"EMAIL\": r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "    \"PHONE\": r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b',\n",
    "    \"PRODUCT_CODE\": r'\\b[A-Z]{2,3}-\\d{4,6}\\b',\n",
    "    \"URL\": r'https?://[^\\s]+'\n",
    "}\n",
    "\n",
    "# Initialize custom detector\n",
    "custom_detector = CustomEntityDetector(patterns=custom_patterns)\n",
    "\n",
    "# Sample text with custom entities\n",
    "custom_text = \"\"\"\n",
    "For support, contact support@apple.com or call 1-800-692-7753.\n",
    "Order product SKU-12345 from https://store.apple.com.\n",
    "Technical inquiries: tech@apple.com or visit our website.\n",
    "\"\"\"\n",
    "\n",
    "print(\" Custom Entity Detection:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for entity_type in custom_patterns.keys():\n",
    "    entities = custom_detector.detect_custom_entities(custom_text, entity_type)\n",
    "    \n",
    "    if entities:\n",
    "        print(f\"\\n{entity_type}:\")\n",
    "        for entity in entities:\n",
    "            entity_text = entity.get('text', entity.get('entity', '')) if isinstance(entity, dict) else entity.text\n",
    "            print(f\"  ‚Ä¢ {entity_text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 8: Batch Processing\n",
    "\n",
    "Process multiple documents efficiently using batch processing capabilities.\n",
    "\n",
    "### Benefits of Batch Processing:\n",
    "\n",
    "- **Performance**: Process multiple documents in one call\n",
    "- **Consistency**: Same configuration applied to all documents\n",
    "- **Efficiency**: Reduced overhead from initialization\n",
    "- **Scalability**: Handle large document collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch Processing Results:\n",
      "\n",
      "================================================================================\n",
      "\n",
      " Document 1:\n",
      "   Text: Apple Inc. released the iPhone 15 in September 202...\n",
      "   Entities: 2\n",
      "\n",
      " Document 2:\n",
      "   Text: Microsoft announced Azure AI updates at Build 2023...\n",
      "   Entities: 3\n",
      "\n",
      " Document 3:\n",
      "   Text: Google's Sundar Pichai spoke at I/O 2023 in Mounta...\n",
      "   Entities: 5\n",
      "\n",
      " Document 4:\n",
      "   Text: Tesla's Elon Musk unveiled the Cybertruck in Austi...\n",
      "   Entities: 5\n",
      "\n",
      " Document 5:\n",
      "   Text: Amazon Web Services launched new features in North...\n",
      "   Entities: 2\n",
      "\n",
      " Batch Processing Summary:\n",
      "----------------------------------------\n",
      "Documents processed: 5\n",
      "Total entities: 17\n",
      "Average per document: 3.4\n",
      "\n",
      " Entity Type Distribution:\n",
      "  ORG: 5\n",
      "  GPE: 5\n",
      "  DATE: 3\n",
      "  PERSON: 2\n",
      "  PRODUCT: 1\n",
      "  LOC: 1\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Sample document collection\n",
    "documents = [\n",
    "    \"Apple Inc. released the iPhone 15 in September 2023.\",\n",
    "    \"Microsoft announced Azure AI updates at Build 2023 in Seattle.\",\n",
    "    \"Google's Sundar Pichai spoke at I/O 2023 in Mountain View, California.\",\n",
    "    \"Tesla's Elon Musk unveiled the Cybertruck in Austin, Texas.\",\n",
    "    \"Amazon Web Services launched new features in Northern Virginia.\"\n",
    "]\n",
    "\n",
    "print(\" Batch Processing Results:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Process all documents\n",
    "batch_results = ner.process_batch(documents)\n",
    "\n",
    "# Analyze results\n",
    "total_entities = 0\n",
    "entity_type_counts = {}\n",
    "\n",
    "for i, (doc, entities) in enumerate(zip(documents, batch_results), 1):\n",
    "    total_entities += len(entities)\n",
    "    \n",
    "    print(f\"\\n Document {i}:\")\n",
    "    print(f\"   Text: {doc[:50]}...\")\n",
    "    print(f\"   Entities: {len(entities)}\")\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_type = entity.get('type', entity.get('label', 'Unknown')) if isinstance(entity, dict) else entity.label\n",
    "        entity_type_counts[entity_type] = entity_type_counts.get(entity_type, 0) + 1\n",
    "\n",
    "print(f\"\\n Batch Processing Summary:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Documents processed: {len(documents)}\")\n",
    "print(f\"Total entities: {total_entities}\")\n",
    "print(f\"Average per document: {total_entities/len(documents):.1f}\")\n",
    "\n",
    "print(\"\\n Entity Type Distribution:\")\n",
    "for entity_type, count in sorted(entity_type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {entity_type}: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 9: Best Practices & Tips\n",
    "\n",
    "###  Choosing the Right Method\n",
    "\n",
    "1. **Start with ML (spaCy)** for general text\n",
    "2. **Use patterns/regex** for structured data (IDs, codes)\n",
    "3. **Try HuggingFace** for domain-specific needs\n",
    "4. **Consider LLM** for complex, custom entity types\n",
    "\n",
    "### Ô∏è Optimizing Performance\n",
    "\n",
    "- **Set appropriate confidence thresholds** (0.7-0.8 for production)\n",
    "- **Use batch processing** for multiple documents\n",
    "- **Enable merge_overlapping** to reduce duplicates\n",
    "- **Cache extractors** instead of recreating them\n",
    "\n",
    "###  Common Pitfalls to Avoid\n",
    "\n",
    "-  **Don't** use very low confidence thresholds (< 0.5)\n",
    "-  **Don't** process one document at a time in loops\n",
    "-  **Don't** ignore entity metadata (contains useful info)\n",
    "-  **Don't** forget to handle extraction errors\n",
    "\n",
    "###  When to Use Each Class\n",
    "\n",
    "| Use Case | Recommended Class |\n",
    "|----------|-------------------|\n",
    "| Quick extraction | `NERExtractor` |\n",
    "| Fine-tuned control | `NamedEntityRecognizer` |\n",
    "| Grouping entities | `EntityClassifier` |\n",
    "| Quality assessment | `EntityConfidenceScorer` |\n",
    "| Domain-specific | `CustomEntityDetector` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "In this notebook, you've learned how to:\n",
    "\n",
    " **Extract entities** using `NERExtractor` and `NamedEntityRecognizer`  \n",
    " **Compare different extraction methods** (pattern, regex, ML, HuggingFace, LLM)  \n",
    " **Classify and group entities** with `EntityClassifier`  \n",
    " **Score entity confidence** using `EntityConfidenceScorer`  \n",
    " **Create custom patterns** with `CustomEntityDetector`  \n",
    " **Process documents in batch** for efficiency  \n",
    " **Apply best practices** for production use  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Multiple methods available**: Choose based on your needs (speed vs accuracy)\n",
    "2. **Configuration matters**: Tune parameters for optimal results\n",
    "3. **Confidence is key**: Use thresholds to filter low-quality extractions\n",
    "4. **Custom patterns work**: For domain-specific entities\n",
    "5. **Batch processing scales**: Process multiple documents efficiently\n",
    "\n",
    "### Next Steps\n",
    "\n",
    " **Next Notebook**: [06_Relation_Extraction.ipynb](./06_Relation_Extraction.ipynb)  \n",
    "Learn how to extract relationships between the entities you've identified!\n",
    "\n",
    " **Further Reading**:\n",
    "- [Semantic Extract API Reference](https://semantica.readthedocs.io/reference/semantic_extract/)\n",
    "- [Advanced Extraction Techniques](../advanced/01_Advanced_Extraction.ipynb)\n",
    "- [Building Knowledge Graphs](./07_Building_Knowledge_Graphs.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or Issues?** Check out our [GitHub repository](https://github.com/Hawksight-AI/semantica) or [documentation](https://semantica.readthedocs.io)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
