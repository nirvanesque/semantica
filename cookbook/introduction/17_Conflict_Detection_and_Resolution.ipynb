{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conflict Detection and Resolution\n",
    "\n",
    "## Overview\n",
    "\n",
    "In real-world Knowledge Graph construction, data often comes from multiple heterogeneous sources (databases, APIs, files, streams). These sources may provide conflicting information about the same entities or relationships. \n",
    "\n",
    "The **Semantica Conflict Detection and Resolution** module (`semantica.conflicts`) provides a comprehensive suite of tools to identifying, analyzing, and resolving these discrepancies to ensure high data quality and trust.\n",
    "\n",
    "**Key Capabilities:**\n",
    "- **Conflict Detection**: Identify value mismatches, type inconsistencies, and temporal contradictions.\n",
    "- **Source Tracking**: Trace every piece of data back to its origin with credibility scoring.\n",
    "- **Resolution Strategies**: Apply automated strategies like voting, credibility weighting, or recency.\n",
    "- **Investigation Guides**: Generate human-readable guides for complex conflicts requiring manual review.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Ensure Semantica is installed:\n",
    "\n",
    "```bash\n",
    "pip install semantica\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantica.conflicts import (\n",
    "    ConflictDetector,\n",
    "    ConflictResolver,\n",
    "    SourceTracker,\n",
    "    ConflictAnalyzer,\n",
    "    InvestigationGuideGenerator,\n",
    "    ResolutionStrategy\n",
    ")\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Simulating Multi-Source Data\n",
    "\n",
    "Let's simulate a scenario where we receive data about the same person from three different sources: an HR database, a LinkedIn scrape, and a public directory. Note the discrepancies in `birth_date` and `department`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simulated data sources\n",
    "sources = {\n",
    "    \"hr_db\": {\"credibility\": 0.95, \"type\": \"internal_database\"},\n",
    "    \"linkedin_scrape\": {\"credibility\": 0.60, \"type\": \"web_scrape\"},\n",
    "    \"public_dir\": {\"credibility\": 0.40, \"type\": \"public_api\"}\n",
    "}\n",
    "\n",
    "# Define entities from these sources\n",
    "entity_records = [\n",
    "    {\n",
    "        \"id\": \"emp_001\",\n",
    "        \"name\": \"John Doe\",\n",
    "        \"birth_date\": \"1980-05-15\",\n",
    "        \"department\": \"Engineering\",\n",
    "        \"source\": \"hr_db\",\n",
    "        \"timestamp\": \"2023-01-01T10:00:00\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"emp_001\",\n",
    "        \"name\": \"Jonathan Doe\",\n",
    "        \"birth_date\": \"1980-05-15\",\n",
    "        \"department\": \"Software Engineering\",\n",
    "        \"source\": \"linkedin_scrape\",\n",
    "        \"timestamp\": \"2023-06-15T14:30:00\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"emp_001\",\n",
    "        \"name\": \"John Doe\",\n",
    "        \"birth_date\": \"1982-05-15\",  # Conflict!\n",
    "        \"department\": \"Engineering\",\n",
    "        \"source\": \"public_dir\",\n",
    "        \"timestamp\": \"2022-12-01T09:00:00\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(entity_records)} records for Employee 001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Tracking Sources\n",
    "\n",
    "Before detecting conflicts, we register our sources with the `SourceTracker`. This allows the system to factor in source credibility during resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tracker = SourceTracker()\n",
    "\n",
    "# Register sources with their metadata and credibility scores\n",
    "for source_id, metadata in sources.items():\n",
    "    source_tracker.register_source(\n",
    "        source_id=source_id,\n",
    "        source_type=metadata[\"type\"],\n",
    "        credibility_score=metadata[\"credibility\"]\n",
    "    )\n",
    "\n",
    "print(\"Sources registered successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Detecting Conflicts\n",
    "\n",
    "Now we use `ConflictDetector` to identify discrepancies. We'll check for value conflicts in `birth_date` and `department`.\n",
    "\n",
    "The detector compares values across all records for the same entity ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ConflictDetector()\n",
    "\n",
    "# Detect conflicts for specific properties\n",
    "conflicts = []\n",
    "\n",
    "# Check birth_date\n",
    "dob_conflicts = detector.detect_value_conflicts(entity_records, \"birth_date\")\n",
    "conflicts.extend(dob_conflicts)\n",
    "\n",
    "# Check department\n",
    "dept_conflicts = detector.detect_value_conflicts(entity_records, \"department\")\n",
    "conflicts.extend(dept_conflicts)\n",
    "\n",
    "print(f\"Detected {len(conflicts)} conflicts:\")\n",
    "for conflict in conflicts:\n",
    "    print(f\"- {conflict.conflict_type.value}: {conflict.property_name} for {conflict.entity_id}\")\n",
    "    print(f\"  Values: {conflict.conflicting_values}\")\n",
    "    print(f\"  Severity: {conflict.severity}\")\n",
    "    print(\"--- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyzing Patterns\n",
    "\n",
    "The `ConflictAnalyzer` can help identify systemic issues, such as a specific source consistently contradicting others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = ConflictAnalyzer()\n",
    "analysis = analyzer.analyze_conflicts(conflicts)\n",
    "\n",
    "print(\"Conflict Analysis Summary:\")\n",
    "print(f\"Total Conflicts: {analysis['total_conflicts']}\")\n",
    "print(f\"By Type: {analysis['by_type']}\")\n",
    "print(f\"By Severity: {analysis['by_severity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Resolving Conflicts\n",
    "\n",
    "We can resolve conflicts using different strategies. \n",
    "\n",
    "### Strategy A: Voting\n",
    "Uses the most frequent value. Useful when you have many sources of equal standing.\n",
    "\n",
    "### Strategy B: Credibility Weighted\n",
    "Prefers values from trusted sources (like our HR DB) over lower-trust sources (public directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver = ConflictResolver()\n",
    "\n",
    "# Need to link the source tracker to the resolver for credibility strategies\n",
    "resolver.set_source_tracker(source_tracker)\n",
    "\n",
    "print(\"--- Resolution: Voting ---\")\n",
    "voting_results = resolver.resolve_conflicts(conflicts, strategy=ResolutionStrategy.VOTING)\n",
    "for res in voting_results:\n",
    "    print(f\"Property: {res.metadata.get('property_name')}\")\n",
    "    print(f\"Resolved Value: {res.resolved_value}\")\n",
    "    print(f\"Confidence: {res.confidence:.2f}\")\n",
    "\n",
    "print(\"\\n--- Resolution: Credibility Weighted ---\")\n",
    "# This should favor the HR DB value for birth_date\n",
    "credibility_results = resolver.resolve_conflicts(conflicts, strategy=ResolutionStrategy.CREDIBILITY_WEIGHTED)\n",
    "for res in credibility_results:\n",
    "    print(f\"Property: {res.metadata.get('property_name')}\")\n",
    "    print(f\"Resolved Value: {res.resolved_value}\")\n",
    "    print(f\"Confidence: {res.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generating Investigation Guides\n",
    "\n",
    "For critical conflicts or those with low resolution confidence, manual intervention is needed. The `InvestigationGuideGenerator` creates a structured guide for human analysts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide_generator = InvestigationGuideGenerator()\n",
    "\n",
    "# Generate a guide for the first conflict (e.g., birth_date)\n",
    "guide = guide_generator.generate_guide(conflicts[0])\n",
    "\n",
    "print(f\"Investigation Guide for {guide.conflict_id}:\")\n",
    "print(f\"Title: {guide.title}\")\n",
    "print(\"Steps:\")\n",
    "for i, step in enumerate(guide.steps, 1):\n",
    "    print(f\"{i}. {step.description} (Action: {step.action_type})\")\n",
    "\n",
    "print(\"\\nRecommended Checks:\")\n",
    "for check in guide.checklist:\n",
    "    print(f\"[ ] {check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored how to:\n",
    "1.  **Detect** conflicts in multi-source data.\n",
    "2.  **Track** data provenance and source credibility.\n",
    "3.  **Resolve** conflicts using automated strategies tailored to your data governance needs.\n",
    "4.  **Investigate** complex issues with generated guides.\n",
    "\n",
    "By integrating these steps into your pipeline, you ensure your Knowledge Graph remains accurate, consistent, and trustworthy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
